{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T04:28:43.263206Z",
     "start_time": "2024-06-07T04:28:39.941484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def login_to_huggingface() -> None:\n",
    "    login(os.environ.get(\"HUGGINGFACE_API_KEY\"))\n",
    "    return\n",
    "\n",
    "login_to_huggingface()"
   ],
   "id": "5c0e5c6a376ddf0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/qcqced/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T11:23:31.710571Z",
     "start_time": "2024-05-25T11:23:27.940227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_model = torch.load('./saved/arxiv_clm_4096_llama2_7b_hf_state_dict.pth')\n",
    "for key in test_model.keys():\n",
    "    print(key)"
   ],
   "id": "7172b94f4feffe35",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T11:24:08.863609Z",
     "start_time": "2024-05-25T11:24:08.860586Z"
    }
   },
   "cell_type": "code",
   "source": "list(test_model.keys())[-1]",
   "id": "78f6219c635d4e57",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-25T10:50:37.968648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_config(AutoConfig.from_pretrained('meta-llama/Llama-2-7b-hf'))\n",
    "\n",
    "for k in model.state_dict().keys():\n",
    "    print(k)"
   ],
   "id": "1d41449a7170bf79",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "\"\"\" rename model attr name  \"\"\"",
   "id": "d07d3d4d4c5121a2",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T15:46:55.298497Z",
     "start_time": "2024-05-29T15:46:55.295985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def convert_to_latex(text: str) -> str:\n",
    "    pattern = r'(\\b\\w+\\b)(\\d*)(?=\\()' \n",
    "    return re.sub(pattern, r'\\\\text{\\1}_{\\2}', text)\n",
    "\n",
    "example_text = \"\"\"FFN(x) = max(0, xW1 + b1)W2 + b2 (2)\"\"\"\n",
    "\n",
    "latex_lines = convert_to_latex(example_text.strip())\n",
    "print(latex_lines)"
   ],
   "id": "7bf34228ffbfc494",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T22:20:10.259339Z",
     "start_time": "2024-05-31T22:20:10.256752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd"
   ],
   "id": "5a7e10a8e2e42510",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T22:22:56.215466Z",
     "start_time": "2024-05-31T22:22:43.676142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_path = \"dataset_class/datafolder/arxiv_qa/partition/\"\n",
    "df_list = os.listdir(base_path)\n",
    "\n",
    "df = pd.DataFrame(columns=['paper_id', 'doc_id', 'title', 'doc'])\n",
    "for sub_url in df_list:\n",
    "    sub_df = pd.read_csv(base_path + sub_url)\n",
    "    df = pd.concat([df, sub_df])\n",
    "\n",
    "df"
   ],
   "id": "801249e2c357b9bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      paper_id         doc_id  \\\n",
       "0   2307.12976   2307.12976_0   \n",
       "1   2307.12976   2307.12976_1   \n",
       "2   2307.12976   2307.12976_2   \n",
       "3   2307.12976   2307.12976_3   \n",
       "4   2307.12976   2307.12976_4   \n",
       "..         ...            ...   \n",
       "58  2303.11749  2303.11749_58   \n",
       "59  2303.11749  2303.11749_59   \n",
       "60  2303.11749  2303.11749_60   \n",
       "61  2303.11749  2303.11749_61   \n",
       "62  2303.11749  2303.11749_62   \n",
       "\n",
       "                                                title  \\\n",
       "0   Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "1   Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "2   Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "3   Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "4   Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "..                                                ...   \n",
       "58  Detecting Everything in the Open World: Toward...   \n",
       "59  Detecting Everything in the Open World: Toward...   \n",
       "60  Detecting Everything in the Open World: Toward...   \n",
       "61  Detecting Everything in the Open World: Toward...   \n",
       "62  Detecting Everything in the Open World: Toward...   \n",
       "\n",
       "                                                  doc question  \n",
       "0   Evaluating the Ripple Effects of Knowledge Edi...      NaN  \n",
       "1                                            Abstract      NaN  \n",
       "2   Modern language models capture a large body of...      NaN  \n",
       "3   construct RIPPLEEDITS, a diagnos- tic benchmar...      NaN  \n",
       "4   Figure 1: Illustration of the evaluation scope...      NaN  \n",
       "..                                                ...      ...  \n",
       "58  <table><caption>Table 5. Comparison with exist...      NaN  \n",
       "59  <table><caption>Table 6. Ablation study on reg...      NaN  \n",
       "60  <table><thead><th>decouple</th><th>proposal ge...      NaN  \n",
       "61  pij = 1 1 + \\text{exp}_{}(−zT ijej/τ ) /πγ j ,...      NaN  \n",
       "62  References\\n[1] Ankan Bansal, Karan Sikka, Gau...      NaN  \n",
       "\n",
       "[242635 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>doc</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_0</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_1</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_2</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Modern language models capture a large body of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_3</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>construct RIPPLEEDITS, a diagnos- tic benchmar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_4</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Figure 1: Illustration of the evaluation scope...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_58</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>&lt;table&gt;&lt;caption&gt;Table 5. Comparison with exist...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_59</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>&lt;table&gt;&lt;caption&gt;Table 6. Ablation study on reg...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_60</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>&lt;table&gt;&lt;thead&gt;&lt;th&gt;decouple&lt;/th&gt;&lt;th&gt;proposal ge...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_61</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>pij = 1 1 + \\text{exp}_{}(−zT ijej/τ ) /πγ j ,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_62</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>References\\n[1] Ankan Bansal, Karan Sikka, Gau...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242635 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T22:24:44.226166Z",
     "start_time": "2024-05-31T22:24:42.014747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = 'dataset_class/datafolder/arxiv_qa/total/total_paper_chunk.csv'\n",
    "df.to_csv(output_path, index=False)"
   ],
   "id": "4734f8500e142a48",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T09:41:49.886167Z",
     "start_time": "2024-06-07T09:41:48.138619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" load dataset for testing make prompt to generate question-document pairs dataset \"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from generate_question.generate_question import google_gemini_api\n",
    "\n",
    "\n",
    "df = pd.read_csv('dataset_class/datafolder/arxiv_qa/total/total_paper_chunk.csv')\n",
    "df"
   ],
   "id": "88f64aa6dcfa014c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/l_9fgbw95hl79rj750047d1c0000gn/T/ipykernel_1740/639598189.py:11: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('dataset_class/datafolder/arxiv_qa/total/total_paper_chunk.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          paper_id         doc_id  \\\n",
       "0       2307.12976   2307.12976_0   \n",
       "1       2307.12976   2307.12976_1   \n",
       "2       2307.12976   2307.12976_2   \n",
       "3       2307.12976   2307.12976_3   \n",
       "4       2307.12976   2307.12976_4   \n",
       "...            ...            ...   \n",
       "242630  2303.11749  2303.11749_58   \n",
       "242631  2303.11749  2303.11749_59   \n",
       "242632  2303.11749  2303.11749_60   \n",
       "242633  2303.11749  2303.11749_61   \n",
       "242634  2303.11749  2303.11749_62   \n",
       "\n",
       "                                                    title  \\\n",
       "0       Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "1       Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "2       Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "3       Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "4       Evaluating the Ripple Effects of Knowledge Edi...   \n",
       "...                                                   ...   \n",
       "242630  Detecting Everything in the Open World: Toward...   \n",
       "242631  Detecting Everything in the Open World: Toward...   \n",
       "242632  Detecting Everything in the Open World: Toward...   \n",
       "242633  Detecting Everything in the Open World: Toward...   \n",
       "242634  Detecting Everything in the Open World: Toward...   \n",
       "\n",
       "                                                      doc question  \n",
       "0       Evaluating the Ripple Effects of Knowledge Edi...      NaN  \n",
       "1                                                Abstract      NaN  \n",
       "2       Modern language models capture a large body of...      NaN  \n",
       "3       construct RIPPLEEDITS, a diagnos- tic benchmar...      NaN  \n",
       "4       Figure 1: Illustration of the evaluation scope...      NaN  \n",
       "...                                                   ...      ...  \n",
       "242630  <table><caption>Table 5. Comparison with exist...      NaN  \n",
       "242631  <table><caption>Table 6. Ablation study on reg...      NaN  \n",
       "242632  <table><thead><th>decouple</th><th>proposal ge...      NaN  \n",
       "242633  pij = 1 1 + \\text{exp}_{}(−zT ijej/τ ) /πγ j ,...      NaN  \n",
       "242634  References\\n[1] Ankan Bansal, Karan Sikka, Gau...      NaN  \n",
       "\n",
       "[242635 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>doc</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_0</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_1</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_2</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Modern language models capture a large body of...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_3</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>construct RIPPLEEDITS, a diagnos- tic benchmar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2307.12976</td>\n",
       "      <td>2307.12976_4</td>\n",
       "      <td>Evaluating the Ripple Effects of Knowledge Edi...</td>\n",
       "      <td>Figure 1: Illustration of the evaluation scope...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242630</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_58</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>&lt;table&gt;&lt;caption&gt;Table 5. Comparison with exist...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242631</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_59</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>&lt;table&gt;&lt;caption&gt;Table 6. Ablation study on reg...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242632</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_60</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>&lt;table&gt;&lt;thead&gt;&lt;th&gt;decouple&lt;/th&gt;&lt;th&gt;proposal ge...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242633</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_61</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>pij = 1 1 + \\text{exp}_{}(−zT ijej/τ ) /πγ j ,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242634</th>\n",
       "      <td>2303.11749</td>\n",
       "      <td>2303.11749_62</td>\n",
       "      <td>Detecting Everything in the Open World: Toward...</td>\n",
       "      <td>References\\n[1] Ankan Bansal, Karan Sikka, Gau...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242635 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:31:08.006422Z",
     "start_time": "2024-06-07T09:41:49.887324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df[1500:2000]\n",
    "question = [google_gemini_api(title=row['title'], context=row['doc'], foundation_model='gemini-1.5-flash') for i, row in tqdm(df.iterrows(), total=len(df))]\n",
    "df['question'] = question\n",
    "df"
   ],
   "id": "49e838e291ada7a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17ac739bbe1942c0a2a2a0e6da128f4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n",
      "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m df \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;241m1500\u001B[39m:\u001B[38;5;241m2000\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m question \u001B[38;5;241m=\u001B[39m [google_gemini_api(title\u001B[38;5;241m=\u001B[39mrow[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m], context\u001B[38;5;241m=\u001B[39mrow[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdoc\u001B[39m\u001B[38;5;124m'\u001B[39m], foundation_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgemini-1.5-flash\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m i, row \u001B[38;5;129;01min\u001B[39;00m tqdm(df\u001B[38;5;241m.\u001B[39miterrows(), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(df))]\n\u001B[1;32m      3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m question\n\u001B[1;32m      4\u001B[0m df\n",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      1\u001B[0m df \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;241m1500\u001B[39m:\u001B[38;5;241m2000\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m question \u001B[38;5;241m=\u001B[39m [\u001B[43mgoogle_gemini_api\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtitle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdoc\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfoundation_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgemini-1.5-flash\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m i, row \u001B[38;5;129;01min\u001B[39;00m tqdm(df\u001B[38;5;241m.\u001B[39miterrows(), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(df))]\n\u001B[1;32m      3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m question\n\u001B[1;32m      4\u001B[0m df\n",
      "File \u001B[0;32m~/Desktop/GitHub/arxiv_qa/generate_question/generate_question.py:119\u001B[0m, in \u001B[0;36mgoogle_gemini_api\u001B[0;34m(title, context, foundation_model, temperature)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    110\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124m[title]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mtitle\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m[context]\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mcontext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;124m    You\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mre a question machine. Read the context given above and generate the right question.\u001B[39m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;124m    Questions should also be able to capture the features or characteristics of a given context.\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;124m    If you want to ask multiple questions, please separate them with spaces without newlines.\u001B[39m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m--> 119\u001B[0m     \u001B[43mget_random_sleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# for avoiding the \"call api limit\"\u001B[39;00m\n\u001B[1;32m    120\u001B[0m     response \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate_content(\n\u001B[1;32m    121\u001B[0m         contents\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m    122\u001B[0m         generation_config\u001B[38;5;241m=\u001B[39mgeneration_config,\n\u001B[1;32m    123\u001B[0m     )\n\u001B[1;32m    124\u001B[0m     datasets \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n",
      "File \u001B[0;32m~/Desktop/GitHub/arxiv_qa/generate_question/generate_question.py:25\u001B[0m, in \u001B[0;36mget_random_sleep\u001B[0;34m(ls, ms)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\" get random sleep time between 5 and 10 seconds\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \n\u001B[1;32m     20\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03m    ls: least time to sleep this process\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03m    ms: max time to sleep this process\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m sleep_time \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39muniform(ls, ms)\n\u001B[0;32m---> 25\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43msleep_time\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T10:31:08.007395Z",
     "start_time": "2024-06-07T10:31:08.007331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = 'dataset_class/datafolder/arxiv_qa/total/1500_2000_test_q_doc.csv'\n",
    "df.to_csv(output_path, index=False)"
   ],
   "id": "3218ae26d5e53f95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def google_gemini_api(\n",
    "    prompt: str,\n",
    "    foundation_model: str = 'gemini-pro',\n",
    "    temperature: float = 0\n",
    ") -> str:\n",
    "    \"\"\" make Arxiv Questioning & Answering dataset function with Google AI Gemini API\n",
    "\n",
    "    As you run this function before, you must set up the your own Google API key for the Gemini API.\n",
    "    you can use the gemini-pro-api for free with the Google API key.\n",
    "\n",
    "    we will use the Zero-Shot Learning for generating the QA dataset from the given paper link.\n",
    "    Args:\n",
    "        prompt: str, input prompt for generating the question\n",
    "        foundation_model (str): The foundation model for extracting food ingredients from the given text,\n",
    "                                default is 'gemini-pro'\n",
    "        temperature (float): default 0.0, the temperature value for the diversity of the output text\n",
    "                             (if you set T < 1.0, the output text will be more deterministic, sharpening softmax dist)\n",
    "                             (if you set T > 1.0, the output text will be more diverse, flattening softmax dist)\n",
    "\n",
    "    References:\n",
    "        https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/quickstart_colab.ipynb?hl=ko#scrollTo=HTiaTu6O1LRC\n",
    "        https://ai.google.dev/gemini-api/docs/models/gemini?hl=ko\n",
    "        https://ai.google.dev/gemini-api/docs/get-started/python?hl=ko&_gl=1*7ufqxk*_up*MQ..*_ga*MTk2ODk3NDQyNi4xNzE0OTIwMjcw*_ga_P1DBVKWT6V*MTcxNDkyMDI2OS4xLjAuMTcxNDkyMDI2OS4wLjAuOTQwNDMwMTE.\n",
    "        https://ai.google.dev/gemini-api/docs/quickstart?hl=ko&_gl=1*12k4ofq*_up*MQ..*_ga*MTk2ODk3NDQyNi4xNzE0OTIwMjcw*_ga_P1DBVKWT6V*MTcxNDkyMDI2OS4xLjAuMTcxNDkyMDI2OS4wLjAuOTQwNDMwMTE.\n",
    "        https://ai.google.dev/api/python/google/generativeai/GenerativeModel?_gl=1*1ajz3qu*_up*MQ..*_ga*MTk2ODk3NDQyNi4xNzE0OTIwMjcw*_ga_P1DBVKWT6V*MTcxNDkyNDAyOC4yLjAuMTcxNDkyNDAyOC4wLjAuMTkwOTQyMjU0#generate_content\n",
    "    \"\"\"\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "    model = genai.GenerativeModel(foundation_model)\n",
    "    generation_config = genai.types.GenerationConfig(\n",
    "        candidate_count=1,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    datasets = ''\n",
    "    try:\n",
    "        get_random_sleep(8, 10)  # for avoiding the \"call api limit\"\n",
    "        response = model.generate_content(\n",
    "            contents=prompt,\n",
    "            generation_config=generation_config,\n",
    "        )\n",
    "        datasets = response.text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return datasets\n"
   ],
   "id": "db0043753eb46e6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T06:38:25.858555Z",
     "start_time": "2024-06-01T06:38:14.495385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" code cell for prompt testing \"\"\"\n",
    "\n",
    "query = \"\"\"You're a question machine.\\nGroup the context and title together with the same number, read each group of the context and title given above and generate the appropriate question for each group.\\nPlease only return the questions' text, and the number of questions should be between 1 and 5 per individual group.\\nThe total number of tokens per individual group should be no more than 100 tokens.\\nThe sum of all groups tokens for all questions should be same as your output's max token length.\\nIf you want to ask multiple questions, please separate them with spaces without newlines.\\nSeparate questions for different groups with line breaks.\\nQuestions should capture the features or characteristics of the given context.\\nThe purpose of asking you to create questions is to create a dataset of question-document pairs.\\nPlease create with purpose and generate creative, informative, and diverse questions.\\nDo not return questions that are too similar to each other or too general.\"\"\"\n",
    "\n",
    "titles, contexts = df.title.tolist()[0:10], df.doc.tolist()[0:10]\n",
    "dataset = list(zip(titles, contexts))\n",
    "\n",
    "prompt = \"\"\n",
    "chunk_size = 10\n",
    "for i in range(0, len(dataset), chunk_size):\n",
    "    for j, data in enumerate(dataset[i:i+chunk_size]):\n",
    "        title, context = data\n",
    "        prompt += f\"[title{j}]\\n{title}\\n\\n[context{j}]\\n{context}\\n\\n\"\n",
    "    \n",
    "    prompt += query\n",
    "    print(prompt)\n",
    "    result = google_gemini_api(\n",
    "        prompt=prompt,\n",
    "        foundation_model=\"gemini-1.5-flash\"\n",
    "    )\n",
    "    \n",
    "result"
   ],
   "id": "709863e977855713",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[title0]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context0]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models\n",
      "Roi Cohen1 Eden Biran1 Ori Yoran1 Amir Globerson1,2 Mor Geva1,2, 1Blavatnik School of Computer Science, Tel Aviv University 2Google Research {roi1, edenbiran, oriy}@mail.tau.ac.il, {gamir, morgeva}@tauex.tau.ac.il\n",
      "\n",
      "[title1]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context1]\n",
      "Abstract\n",
      "\n",
      "[title2]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context2]\n",
      "Modern language models capture a large body of factual knowledge. However, some facts can be incorrectly induced or become obsolete over time, resulting in factually in- correct generations. This has led to the de- velopment of various editing methods that allow updating facts encoded by the model. Evaluation of these methods has primarily focused on testing whether an individual fact has been successfully injected, and if sim- ilar predictions for other subjects have not changed. Here we argue that such evaluation is limited, since injecting one fact (e.g. “Jack Depp is the son of Johnny Depp”) introduces a “ripple effect” in the form of additional facts that the model needs to update (e.g., “Jack Depp is the sibling of Lily-Rose Depp”). To address this, we propose novel evaluation criteria that consider the implications of an edit on related facts. Using these criteria, we then construct RIPPLEEDITS, a diagnos- tic benchmark of 5K factual edits, capturing various types of ripple effects. We evaluate\n",
      "\n",
      "[title3]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context3]\n",
      "construct RIPPLEEDITS, a diagnos- tic benchmark of 5K factual edits, capturing various types of ripple effects. We evaluate prominent editing methods on RIPPLEED- ITS, showing that they fail to introduce con- sistent changes in the model’s knowledge. In addition, we find that a simple in-context editing baseline obtains the best scores on our benchmark, suggesting a promising re- search direction for model editing.1\n",
      "\n",
      "[title4]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context4]\n",
      "Figure 1: Illustration of the evaluation scope of RIP- PLEEDITS, compared to existing knowledge editing benchmarks. For a given factual edit, we consider the “ripple effect” of the edit on the model’s knowledge.\n",
      "\n",
      "[title5]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context5]\n",
      "Introduction\n",
      "model may be incorrect or become outdated over time, potentially affecting the model’s performance on downstream tasks, its reliability and its usability (Dhingra et al., 2022; Lazaridou et al., 2021; Jang et al., 2022).\n",
      "Modern language models (LMs) capture a large volume of factual knowledge in their parameters, which can be effectively utilized in downstream tasks (Petroni et al., 2019; Roberts et al., 2020; Shin et al., 2020; Razniewski et al., 2021; Heinzerling and Inui, 2021; Kadavath et al., 2022; Cohen et al., 2023a). However, factual beliefs captured by the\n",
      "∗Work done at Google DeepMind. 1We release RIPPLEEDITS and our code at https://\n",
      "github.com/edenbiran/RippleEdits.\n",
      "\n",
      "[title6]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context6]\n",
      "∗Work done at Google DeepMind. 1We release RIPPLEEDITS and our code at https://\n",
      "github.com/edenbiran/RippleEdits.\n",
      "This limitation has prompted research on knowl- edge editing (KE) methods, which modify LMs to fix their factual errors (we provide a formal defini- tion in §2). Knowledge editing work has focused on applying factual updates to LMs. Given an entity-relation-object triplet (e, r, o) representing a fact (e.g. “Lionel Messi plays for the Inter Mi- ami team”), recent work proposed various methods (Mitchell et al., 2022a; Meng et al., 2022, 2023; Hernandez et al., 2023b; Si et al., 2023) to inject\n",
      "\n",
      "[title7]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context7]\n",
      "this fact into the parameters of a given LM, while “overriding” beliefs the model might have on e and r (e.g. that Messi plays for Paris Saint-Germain). A key question with KE is how to evaluate the success of such editing operations. The most basic “sanity-check” is that the model correctly completes (e, r, ?), as well as other paraphrases of this task, with o. However, this is not enough as an evalua- tion, since one needs to check that the model did not distort other facts. Indeed, the standard evalua- tion protocol (Mitchell et al., 2022b; Meng et al., 2022, 2023) for KE focuses on these two aspects of correctly completing various paraphrases of the new fact, as well as ensuring that other unrelated facts have not been changed.\n",
      "\n",
      "[title8]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context8]\n",
      "In this work, we argue that to evaluate model edits, one should go beyond the single fact that was edited and check that other facts that are logically derived from the edit were also changed accord- ingly. For example, if z is the mother of e, then the children of z are the siblings of e. Consequently, once we modify the belief of a certain model that z → z′ is the mother of e, then we should also en- sure that the model’s belief regarding the siblings of e is also correct. Fig. 1 illustrates another ex- ample, where editing the Team for which Lionel Messi plays modifies other related facts, such as his country of residence, while other facts should be retained. We refer to such changes that are im- plied by a factual edit as “ripple effects”.\n",
      "\n",
      "[title9]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models.pdf\n",
      "\n",
      "[context9]\n",
      "To account for ripple effects in the evaluation of factual edits, we propose six concrete evaluation criteria (see §3, Fig. 2), for testing which facts other than the edit itself should be modified or retained post-editing. Our tests evaluate how well the model integrates the edit with the rest of its knowledge, through queries that involve logical reasoning, complex composition of facts with the edit as an intermediate step, subject aliasing, and specificity across relations.\n",
      "Building upon these criteria, we create RIP- PLEEDITS, a new benchmark for comprehensive evaluation of KE of LMs (see §4). RIPPLEEDITS includes 5K entries, each consisting of a factual edit, along with a set of test queries that check if the edit was successful in terms of its ripple effect. Moreover, RIPPLEEDITS contains meta-data for each edit, including information about the times- tamp of the edit (i.e., recent versus old), and the popularity of the entities (i.e., head versus tail).\n",
      "We use RIPPLEEDITS to evaluate three popular\n",
      "\n",
      "You're a question machine.\n",
      "Group the context and title together with the same number, read each group of the context and title given above and generate the appropriate question for each group.\n",
      "Please only return the questions' text, and the number of questions should be between 1 and 5 per individual group.\n",
      "The total number of tokens per individual group should be no more than 100 tokens.\n",
      "The sum of all groups tokens for all questions should be same as your output's max token length.\n",
      "If you want to ask multiple questions, please separate them with spaces without newlines.\n",
      "Separate questions for different groups with line breaks.\n",
      "Questions should capture the features or characteristics of the given context.\n",
      "The purpose of asking you to create questions is to create a dataset of question-document pairs.\n",
      "Please create with purpose and generate creative, informative, and diverse questions.\n",
      "Do not return questions that are too similar to each other or too general.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the main focus of this research paper?\\n\\nWhat are the limitations of existing evaluation methods for knowledge editing in language models?\\n\\nWhat is the proposed solution to address the limitations of existing evaluation methods?\\n\\nWhat are the key features of the RIPPLEEDITS benchmark?\\n\\nWhat are the six evaluation criteria proposed in the paper to assess the ripple effects of knowledge editing? \\n\\nWhat are the main findings of the evaluation of prominent editing methods on RIPPLEEDITS?\\n\\nWhat is the main contribution of this research paper? \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T07:20:03.252346Z",
     "start_time": "2024-06-01T07:18:54.782275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\" code cell 2 for second version of prompt testing\n",
    "\n",
    "first ver: title, context\n",
    "second ver: context\n",
    "\"\"\"\n",
    "\n",
    "query = \"\"\"You're a question machine.\\nThe given text has a number of contexts numbered. Create questions that are appropriate for each context.\\nQuestions should capture the features or characteristics of the given context.\\nThe purpose of asking you to create questions is to create a dataset of question-document pairs.\\nPlease create with purpose and generate creative, informative, and meaningful questions.\\nDo not return questions that are too similar to each other or too general.\\nPlease only return the questions' text, and the number of questions should be between 1 and 5 per single individual context group. If you want to ask more than one questions about single context, please separate them with space, not newlines.\\nEach context's questions should be no more than 100 tokens.\\nSeparate questions for different context group with line breaks.\"\"\"\n",
    "\n",
    "\n",
    "dataset = df.doc.tolist()[0:10]\n",
    "\n",
    "prompt = \"\"\n",
    "chunk_size = 10\n",
    "for i in range(0, len(dataset), chunk_size):\n",
    "    for j, data in enumerate(dataset[i:i+chunk_size]):\n",
    "        prompt += f\"[context{j}]\\n{data}\\n\\n\"\n",
    "    \n",
    "    prompt += query\n",
    "    print(prompt)\n",
    "    result = google_gemini_api(\n",
    "        prompt=prompt,\n",
    "        foundation_model=\"gemini-1.5-flash\"\n",
    "    )\n",
    "    \n",
    "result"
   ],
   "id": "72e6a2ccc66a3644",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[context0]\n",
      "Evaluating the Ripple Effects of Knowledge Editing in Language Models\n",
      "Roi Cohen1 Eden Biran1 Ori Yoran1 Amir Globerson1,2 Mor Geva1,2, 1Blavatnik School of Computer Science, Tel Aviv University 2Google Research {roi1, edenbiran, oriy}@mail.tau.ac.il, {gamir, morgeva}@tauex.tau.ac.il\n",
      "\n",
      "[context1]\n",
      "Abstract\n",
      "\n",
      "[context2]\n",
      "Modern language models capture a large body of factual knowledge. However, some facts can be incorrectly induced or become obsolete over time, resulting in factually in- correct generations. This has led to the de- velopment of various editing methods that allow updating facts encoded by the model. Evaluation of these methods has primarily focused on testing whether an individual fact has been successfully injected, and if sim- ilar predictions for other subjects have not changed. Here we argue that such evaluation is limited, since injecting one fact (e.g. “Jack Depp is the son of Johnny Depp”) introduces a “ripple effect” in the form of additional facts that the model needs to update (e.g., “Jack Depp is the sibling of Lily-Rose Depp”). To address this, we propose novel evaluation criteria that consider the implications of an edit on related facts. Using these criteria, we then construct RIPPLEEDITS, a diagnos- tic benchmark of 5K factual edits, capturing various types of ripple effects. We evaluate\n",
      "\n",
      "[context3]\n",
      "construct RIPPLEEDITS, a diagnos- tic benchmark of 5K factual edits, capturing various types of ripple effects. We evaluate prominent editing methods on RIPPLEED- ITS, showing that they fail to introduce con- sistent changes in the model’s knowledge. In addition, we find that a simple in-context editing baseline obtains the best scores on our benchmark, suggesting a promising re- search direction for model editing.1\n",
      "\n",
      "[context4]\n",
      "Figure 1: Illustration of the evaluation scope of RIP- PLEEDITS, compared to existing knowledge editing benchmarks. For a given factual edit, we consider the “ripple effect” of the edit on the model’s knowledge.\n",
      "\n",
      "[context5]\n",
      "Introduction\n",
      "model may be incorrect or become outdated over time, potentially affecting the model’s performance on downstream tasks, its reliability and its usability (Dhingra et al., 2022; Lazaridou et al., 2021; Jang et al., 2022).\n",
      "Modern language models (LMs) capture a large volume of factual knowledge in their parameters, which can be effectively utilized in downstream tasks (Petroni et al., 2019; Roberts et al., 2020; Shin et al., 2020; Razniewski et al., 2021; Heinzerling and Inui, 2021; Kadavath et al., 2022; Cohen et al., 2023a). However, factual beliefs captured by the\n",
      "∗Work done at Google DeepMind. 1We release RIPPLEEDITS and our code at https://\n",
      "github.com/edenbiran/RippleEdits.\n",
      "\n",
      "[context6]\n",
      "∗Work done at Google DeepMind. 1We release RIPPLEEDITS and our code at https://\n",
      "github.com/edenbiran/RippleEdits.\n",
      "This limitation has prompted research on knowl- edge editing (KE) methods, which modify LMs to fix their factual errors (we provide a formal defini- tion in §2). Knowledge editing work has focused on applying factual updates to LMs. Given an entity-relation-object triplet (e, r, o) representing a fact (e.g. “Lionel Messi plays for the Inter Mi- ami team”), recent work proposed various methods (Mitchell et al., 2022a; Meng et al., 2022, 2023; Hernandez et al., 2023b; Si et al., 2023) to inject\n",
      "\n",
      "[context7]\n",
      "this fact into the parameters of a given LM, while “overriding” beliefs the model might have on e and r (e.g. that Messi plays for Paris Saint-Germain). A key question with KE is how to evaluate the success of such editing operations. The most basic “sanity-check” is that the model correctly completes (e, r, ?), as well as other paraphrases of this task, with o. However, this is not enough as an evalua- tion, since one needs to check that the model did not distort other facts. Indeed, the standard evalua- tion protocol (Mitchell et al., 2022b; Meng et al., 2022, 2023) for KE focuses on these two aspects of correctly completing various paraphrases of the new fact, as well as ensuring that other unrelated facts have not been changed.\n",
      "\n",
      "[context8]\n",
      "In this work, we argue that to evaluate model edits, one should go beyond the single fact that was edited and check that other facts that are logically derived from the edit were also changed accord- ingly. For example, if z is the mother of e, then the children of z are the siblings of e. Consequently, once we modify the belief of a certain model that z → z′ is the mother of e, then we should also en- sure that the model’s belief regarding the siblings of e is also correct. Fig. 1 illustrates another ex- ample, where editing the Team for which Lionel Messi plays modifies other related facts, such as his country of residence, while other facts should be retained. We refer to such changes that are im- plied by a factual edit as “ripple effects”.\n",
      "\n",
      "[context9]\n",
      "To account for ripple effects in the evaluation of factual edits, we propose six concrete evaluation criteria (see §3, Fig. 2), for testing which facts other than the edit itself should be modified or retained post-editing. Our tests evaluate how well the model integrates the edit with the rest of its knowledge, through queries that involve logical reasoning, complex composition of facts with the edit as an intermediate step, subject aliasing, and specificity across relations.\n",
      "Building upon these criteria, we create RIP- PLEEDITS, a new benchmark for comprehensive evaluation of KE of LMs (see §4). RIPPLEEDITS includes 5K entries, each consisting of a factual edit, along with a set of test queries that check if the edit was successful in terms of its ripple effect. Moreover, RIPPLEEDITS contains meta-data for each edit, including information about the times- tamp of the edit (i.e., recent versus old), and the popularity of the entities (i.e., head versus tail).\n",
      "We use RIPPLEEDITS to evaluate three popular\n",
      "\n",
      "You're a question machine.\n",
      "The given text has a number of contexts numbered. Create questions that are appropriate for each context.\n",
      "Questions should capture the features or characteristics of the given context.\n",
      "The purpose of asking you to create questions is to create a dataset of question-document pairs.\n",
      "Please create with purpose and generate creative, informative, and meaningful questions.\n",
      "Do not return questions that are too similar to each other or too general.\n",
      "Please only return the questions' text, and the number of questions should be between 1 and 5 per single individual context group. If you want to ask more than one questions about single context, please separate them with space, not newlines.\n",
      "Each context's questions should be no more than 100 tokens.\n",
      "Separate questions for different context group with line breaks.\n",
      "504 Deadline Exceeded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
