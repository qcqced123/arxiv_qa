{
    "pipeline_setting": {
        "pipeline_type": "make",
        "work_flow_state": "resume",
        "n_jobs": 4,
        "resume": false,
        "question_generator": "llama",
        "task": "CasualLanguageModel"
    },

    "generate_options": {
        "model_name": "meta-llama/Llama-2-7b-hf",
        "tokenizer_name": "meta-llama/Llama-2-7b-hf",
        "max_len": 4096,
        "max_new_tokens": 512,
        "strategy": "beam",
        "penalty_alpha": 0.6,
        "num_beams": 2,
        "temperature": 1.0,
        "top_k": 50,
        "top_p": 1,
        "repetition_penalty": 2.0,
        "length_penalty": 1.0,
        "no_repeat_ngram_size": 2,
        "do_sample": false,
        "use_cache": true,
        "use_pretrained": true,
        "generate_mode": true,
        "hub": "huggingface",
        "lora": false,
        "qlora": true,
        "lora_rank": 8,
        "lora_alpha": 32,
        "lora_dropout": 0.1,
        "task_type": "None",
        "prompt_tuning": false,
        "layer_norm_eps": 1e-7,
        "attention_probs_dropout_prob": 0.1,
        "hidden_dropout_prob": 0.1,
        "init_weight": "kaiming_normal",
        "initializer_range": 0.02
    },

    "common_settings": {
        "wandb": true,
        "seed": 42,
        "n_gpu": 1,
        "gpu_id": 0,
        "num_workers": 4
    }
}
