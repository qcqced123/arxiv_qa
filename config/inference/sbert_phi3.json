{
    "pipeline_setting": {
        "pipeline_type": "inference",
        "resume": false,
        "task": "CasualLanguageModel",
        "checkpoint_dir": "./saved/arxiv_clm_4096_llama2_7b_hf_state_dict.pth"
    },

    "retriever_options": {
        "retriever": "sentence-transformers/all-MiniLM-L6-v2",
        "max_len": 512,
        "batch_size": 32,
        "num_workers": 4,
        "use_gpu": true,
        "gpu_id": 0,
        "device": "cuda",
        "cache_dir": "./cache"
    },

    "generate_options": {
        "model_name": "microsoft/Phi-3-mini-128k-instruct",
        "tokenizer_name": "microsoft/Phi-3-mini-128k-instruct",
        "max_len": 131072,
        "max_new_tokens": 1024,
        "return_full_text": false,
        "strategy": "beam",
        "num_beams": 5,
        "temperature": 0.7,
        "top_k": 100,
        "top_p": 0.9,
        "penalty_alpha": 1.0,
        "repetition_penalty": 1.0,
        "length_penalty": 2.0,
        "no_repeat_ngram_size": 4,
        "do_sample": true,
        "use_cache": true
    },

    "fine_tune_options": {
        "use_pretrained": true,
        "generate_mode": true,
        "hub": "huggingface",
        "quantization": true,
        "lora": false,
        "qlora": false,
        "lora_rank": 8,
        "lora_alpha": 32,
        "lora_dropout": 0.1,
        "task_type": "None",
        "prompt_tuning": false,
        "prompt_tuning_type": "P-TUNING",
        "num_virtual_tokens": 2,
        "virtual_token_dim": 768,
        "prompt_encoder_hidden_size": 768,
        "layer_norm_eps": 1e-7,
        "attention_probs_dropout_prob": 0.1,
        "hidden_dropout_prob": 0.1,
        "init_weight": "kaiming_normal",
        "initializer_range": 0.02
    },

    "common_settings": {
        "wandb": true,
        "seed": 42,
        "n_gpu": 1,
        "gpu_id": 0,
        "num_workers": 4
    }
}
