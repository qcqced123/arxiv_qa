{
    "pipeline_setting": {
        "pipeline_type": "fine_tune",
        "name": "ArxivMetricLearning",
        "trainer": "TextGenerationTuner",
        "loop": "train_loop",
        "task": "CasualLanguageModel",
        "dataset": "TextGenerationDataset",
        "model_name": "sentence-transformers/all-MiniLM-L6-v2",
        "tokenizer_name": "sentence-transformers/all-MiniLM-L6-v2",
        "resume": false,
        "checkpoint_dir": "./saved/arxiv_clm_4096_llama2_7b_hf_state_dict.pth"
    },

    "fine_tune_options": {
        "use_pretrained": true,
        "hub": "huggingface",
        "max_len": 1536,
        "layer_norm_eps": 1e-7,
        "attention_probs_dropout_prob": 0.1,
        "hidden_dropout_prob": 0.1,
        "init_weight": "kaiming_normal",
        "initializer_range": 0.02,
        "lora": false,
        "qlora": false,
        "prompt_tuning": false
    },

    "data_settings": {
        "datafolder": "arxiv_qa",
        "batching": "random",
        "split_ratio": 0.1,
        "epochs": 1,
        "batch_size": 8,
        "val_batch_size": 8,
        "encoder_reparameterization_type": "LSTM",
        "val_check": 9999999
    },

    "optimizer_options": {
        "optimizer": "AdamW",
        "llrd": false,
        "lr": 2e-4,
        "weight_decay": 1e-2,
        "adam_epsilon": 1e-6,
        "use_bertadam": false,
        "betas": [0.9, 0.999]
    },

    "scheduler_options": {
        "scheduler": "cosine_annealing",
        "batch_scheduler": true,
        "num_cycles": 1,
        "warmup_ratio": 0.1
    },

    "gradient_settings": {
        "amp_scaler": true,
        "gradient_checkpoint": true,
        "clipping_grad": true,
        "n_gradient_accumulation_steps": 1,
        "max_grad_norm": 10
    },

    "loss_options": {
        "losses_fn": "ArcFace",
        "val_losses_fn": "CrossEntropyLoss",
        "reduction": "mean"
    },

    "metrics_options": {
        "metrics": ["accuracy", "f1-score"]
    },

    "common_settings": {
        "wandb": true,
        "seed": 42,
        "n_gpu": 1,
        "gpu_id": 0,
        "num_workers": 4
    },

    "model_utils": {
        "stop_mode": "min",
        "patience": 3,
        "freeze": false,
        "num_freeze": -1,
        "reinit": false,
        "num_reinit": 1
    }
}
